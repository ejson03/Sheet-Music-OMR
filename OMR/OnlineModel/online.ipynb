{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize_inverse(img):\n",
    "    ret, bin_img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    return bin_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "    \"sofa\", \"train\", \"tvmonitor\"]\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "def ml_obj_det(frame):\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)),\n",
    "        0.007843, (300, 300), 127.5)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # draw the prediction on the frame\n",
    "            label = \"{}: {:.2f}%\".format(CLASSES[idx],\n",
    "                confidence * 100)\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                COLORS[idx], 2)\n",
    "            y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "            cv2.putText(frame, label, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def line_detection(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize = 3)\n",
    "    minLineLength = 300\n",
    "    maxLineGap = 10\n",
    "    \n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/2,100,minLineLength,maxLineGap)\n",
    "    \n",
    "    for pt in lines:\n",
    "        x1,y1,x2,y2 = pt[0]\n",
    "        if x2-x1>y2-y1:\n",
    "            cv2.line(frame, (x1,y1),(x2,y2),(0,255,0),2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_lines(frame, vertical_size = 500):\n",
    "    bw = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    bw = binarize_inverse(bw)\n",
    "    horizontal = np.copy(bw)\n",
    "    vertical = np.copy(bw)\n",
    "    # Specify size on horizontal axis\n",
    "    cols = horizontal.shape[1]\n",
    "    horizontal_size = int(cols/30)\n",
    "    # Create structure element for extracting horizontal lines through morphology operations\n",
    "    horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "    # Apply morphology operations\n",
    "    horizontal = cv2.erode(horizontal, horizontalStructure)\n",
    "    horizontal = cv2.dilate(horizontal, horizontalStructure)\n",
    "    \n",
    "    # Specify size on vertical axis\n",
    "    rows = vertical.shape[0]\n",
    "    verticalsize = int(rows/vertical_size)\n",
    "    # Create structure element for extracting vertical lines through morphology operations\n",
    "    verticalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, verticalsize))\n",
    "    # Apply morphology operations\n",
    "    vertical = cv2.erode(vertical, verticalStructure)\n",
    "    vertical = cv2.dilate(vertical, verticalStructure)\n",
    "    # Inverse vertical image\n",
    "    vertical = cv2.bitwise_not(vertical)\n",
    "\n",
    "    # Step 1\n",
    "    edges = cv2.adaptiveThreshold(vertical, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                                cv2.THRESH_BINARY, 3, -2)\n",
    "    # Step 2\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel)\n",
    "    # Step 3\n",
    "    smooth = np.copy(vertical)\n",
    "    # Step 4\n",
    "    smooth = cv2.blur(smooth, (2, 2))\n",
    "    # Step 5\n",
    "    (rows, cols) = np.where(edges != 0)\n",
    "    vertical[rows, cols] = smooth[rows, cols]\n",
    "    # Show final result\n",
    "    return vertical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\ML\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\ML\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../SheetClassification/mobilenetv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_sheet(frame):\n",
    "    ipimg = np.array([cv2.resize(frame, (224, 224))])\n",
    "    output = model.predict(ipimg).flatten()\n",
    "    string = \"\"\n",
    "    if output[0] > output[1]:\n",
    "        string = \"Please point the camera to a sheet music.\"\n",
    "    else:\n",
    "        string = \"Thank You. Processing...\"\n",
    "    frame = cv2.putText(frame, string, (10, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe('./Caffe/deploy.prototxt', './Caffe/mobilenet_iter_73000.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "fps = FPS().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] elapsed time: 834.87\n",
      "[INFO] approx. FPS: 9.33\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    frame = ml_obj_det(frame)\n",
    "#     frame = line_detection(frame)\n",
    "\n",
    "#     frame = detect_sheet(frame)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "    fps.update()\n",
    "\n",
    "fps.stop()\n",
    "print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    " \n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    cv2.imshow('image', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../ScanLineDetection/images/img1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show(remove_lines(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1651, 1275)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
